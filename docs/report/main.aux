\relax 
\citation{angiulli2025aexad}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduzione}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Definizione del Problema e Ipotesi di Ricerca}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Fondamenti teorici}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Anomaly Detection basata su ricostruzione}{4}{}\protected@file@percent }
\citation{angiulli2025aexad}
\citation{angiulli2025aexad}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Il framework AE-XAD}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Inductive bias nelle architetture di visione}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Il framework AE-XAD}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Architettura del modello}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Funzione di perdita AE-XAD}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Pipeline di scoring e localizzazione}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Assunzioni implicite del framework AE-XAD}{7}{}\protected@file@percent }
\citation{angiulli2025aexad}
\@writefile{toc}{\contentsline {section}{\numberline {4}Modifica architetturale: integrazione del Vision Transformer}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Obiettivo della modifica}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Encoder ViT: struttura e adattamento spaziale}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Componenti mantenuti invariati}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Regimi di addestramento dell’encoder ViT}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Encoder ViT completamente frozen}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Encoder ViT completamente trainable}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Differenze strutturali rispetto all’encoder convoluzionale}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Setup sperimentale}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dataset}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Protocollo few-shot supervisionato}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Preprocessing delle immagini}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Data augmentation}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Funzione di perdita}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Ottimizzazione e dettagli di training}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Pipeline di training e test}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Risultati sperimentali}{13}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Risultati per classe su MVTec AD con encoder ViT completamente frozen.}}{14}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:vit_frozen_results}{{1}{14}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Risultati quantitativi per classe (ViT frozen)}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Analisi delle prestazioni image-level}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Analisi delle prestazioni pixel-level}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Relazione tra rilevazione e localizzazione}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Sintesi dei risultati (ViT frozen)}{15}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Risultati per classe su MVTec AD con encoder ViT completamente trainable.}}{16}{}\protected@file@percent }
\newlabel{tab:vit_trainable_results}{{2}{16}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Confronto medio tra encoder ViT frozen e ViT trainable sul dataset MVTec AD.}}{16}{}\protected@file@percent }
\newlabel{tab:vit_frozen_vs_trainable}{{3}{16}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Risultati quantitativi per classe (ViT trainable)}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Confronto tra encoder ViT frozen e ViT trainable}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}Confronto finale con AE-XAD originale}{17}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Confronto medio delle prestazioni sul dataset MVTec AD tra AE-XAD originale (encoder convoluzionale), ViT frozen e ViT trainable.}}{17}{}\protected@file@percent }
\newlabel{tab:final_comparison}{{4}{17}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Analisi qualitativa delle mappe di errore}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Caratteristiche generali delle mappe di errore ViT}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Classi con anomalie estese}{19}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Esempio di mappa di errore per la classe \textit  {tile} con encoder ViT frozen. L’anomalia, di natura estesa e strutturata, produce una concentrazione visivamente riconoscibile dell’errore di ricostruzione. Nonostante una certa diffusione del segnale anche nelle regioni circostanti, la struttura spaziale del difetto risulta preservata, in accordo con i buoni valori di F1-score e IoU osservati.}}{19}{}\protected@file@percent }
\newlabel{fig:tile_vit_frozen}{{1}{19}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Mappa di errore di ricostruzione per la classe \textit  {wood} con encoder ViT frozen. L’errore risulta maggiormente concentrato in corrispondenza delle regioni difettose, sebbene a volte non perfettamente localizzato. Questo comportamento è coerente con le prestazioni quantitative relativamente elevate ottenute per questa classe.}}{20}{}\protected@file@percent }
\newlabel{fig:wood_vit_frozen}{{2}{20}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Esempio di heatmap per la classe \textit  {hazelnut} con encoder ViT frozen. Le anomalie estese generano una risposta di errore chiaramente distinguibile dallo sfondo, confermando che il Vision Transformer riesce a supportare la localizzazione quando il difetto presenta una struttura spaziale marcata.}}{20}{}\protected@file@percent }
\newlabel{fig:tile_vit_frozen}{{3}{20}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Classi con anomalie sottili o localizzate}{21}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Mappa di errore di ricostruzione per la classe \textit  {screw} con encoder ViT frozen. Le anomalie, di dimensioni ridotte e localizzate lungo strutture sottili, non producono una concentrazione spaziale dell’errore. Il segnale risulta diffuso su gran parte dell’immagine, con un contrasto insufficiente tra regioni normali e anomale, rendendo inefficace la sogliatura statistica globale $\mu + \sigma $ e spiegando i bassi valori di F1-score e IoU osservati.}}{21}{}\protected@file@percent }
\newlabel{fig:screw_vit_frozen}{{4}{21}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Heatmap di ricostruzione per la classe \textit  {capsule} con encoder ViT frozen. L’errore di ricostruzione risulta scarsamente correlato alla posizione dell’anomalia, con una distribuzione spaziale uniforme che ostacola la localizzazione pixel-wise.}}{22}{}\protected@file@percent }
\newlabel{fig:capsule_vit_frozen}{{5}{22}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Mappa di errore per la classe \textit  {transistor} con encoder ViT frozen. L’anomalia, di dimensioni ridotte e ad alta frequenza spaziale, non produce una concentrazione localizzata dell’errore. Il segnale risulta diffuso su gran parte dell’immagine, rendendo inefficace la sogliatura globale e spiegando i bassi valori di F1-score e IoU osservati.}}{22}{}\protected@file@percent }
\newlabel{fig:transistor_vit_frozen}{{6}{22}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Esempio di mappa di errore per la classe \textit  {toothbrush} con encoder ViT frozen. La presenza di anomalie sottili e localizzate non si traduce in una risposta di errore spazialmente concentrata, confermando le difficoltà del Vision Transformer nel supportare la pipeline di localizzazione di AE-XAD in questi scenari.}}{23}{}\protected@file@percent }
\newlabel{fig:toothbrush_vit_frozen}{{7}{23}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Confronto qualitativo tra ViT frozen e ViT trainable}{23}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confronto qualitativo tra encoder ViT frozen e trainable per la classe \textit  {tile}. Nel setting trainable si osserva una riduzione del contrasto tra regioni anomale e sfondo, con una mappa di errore più uniforme rispetto alla configurazione frozen.}}{24}{}\protected@file@percent }
\newlabel{fig:qual_tile_frozen_vs_trainable}{{8}{24}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Confronto tra mappe di errore per la classe \textit  {transistor} con encoder ViT frozen e trainable. Il fine-tuning end-to-end porta a una quasi completa soppressione del segnale di errore associato all’anomalia, rendendo inefficace la localizzazione pixel-wise.}}{25}{}\protected@file@percent }
\newlabel{fig:qual_transistor_frozen_vs_trainable}{{9}{25}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Sintesi dell’analisi qualitativa}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Discussione e conclusioni}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Discussione dei risultati}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Ruolo dell’inductive bias}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Frozen vs trainable: implicazioni}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Limiti del lavoro}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Conclusioni e prospettive future}{28}{}\protected@file@percent }
\bibstyle{IEEEtran}
\bibdata{bibliography}
\bibcite{angiulli2025aexad}{1}
\gdef \@abspage@last{30}
