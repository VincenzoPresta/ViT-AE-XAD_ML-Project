\relax 
\citation{angiulli2025aexad}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduzione}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Definizione del Problema e Ipotesi di Ricerca}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Fondamenti teorici}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Anomaly Detection basata su ricostruzione}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Inductive bias nelle architetture di visione}{5}{}\protected@file@percent }
\citation{angiulli2025aexad}
\@writefile{toc}{\contentsline {section}{\numberline {3}Il framework AE-XAD}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Architettura del modello}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Funzione di perdita AE-XAD}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Pipeline di scoring e localizzazione}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Assunzioni implicite del framework AE-XAD}{7}{}\protected@file@percent }
\citation{angiulli2025aexad}
\@writefile{toc}{\contentsline {section}{\numberline {4}Modifica architetturale: integrazione del Vision Transformer}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Obiettivo della modifica}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Encoder ViT: struttura e adattamento spaziale}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Componenti mantenuti invariati}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Regimi di addestramento dell’encoder ViT}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Encoder ViT congelato}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Encoder ViT addestrabile}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Differenze strutturali rispetto all’encoder convoluzionale}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Setup sperimentale}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dataset}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Protocollo few-shot supervisionato}{12}{}\protected@file@percent }
\citation{angiulli2025aexad}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Preprocessing delle immagini}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Data augmentation}{13}{}\protected@file@percent }
\citation{angiulli2025aexad}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Funzione di loss}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Ottimizzazione e dettagli di training}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Pipeline di training e test}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Risultati sperimentali}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Risultati quantitativi per classe (ViT frozen)}{15}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Risultati per classe su MVTec AD con encoder ViT completamente frozen.}}{16}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:vit_frozen_results}{{1}{16}{}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Analisi delle prestazioni image-level}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Analisi delle prestazioni pixel-level}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Relazione tra rilevazione e localizzazione}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Sintesi dei risultati (ViT frozen)}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Risultati quantitativi per classe (ViT trainable)}{17}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Risultati per classe su MVTec AD con encoder ViT completamente trainable.}}{18}{}\protected@file@percent }
\newlabel{tab:vit_trainable_results}{{2}{18}{}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Confronto tra encoder ViT frozen e ViT trainable}{18}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Confronto medio tra encoder ViT frozen e ViT trainable sul dataset MVTec AD.}}{18}{}\protected@file@percent }
\newlabel{tab:vit_frozen_vs_trainable}{{3}{18}{}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}Confronto finale con AE-XAD originale}{19}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Confronto medio delle prestazioni sul dataset MVTec AD tra AE-XAD originale (encoder convoluzionale), ViT frozen e ViT trainable.}}{19}{}\protected@file@percent }
\newlabel{tab:final_comparison}{{4}{19}{}{table.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Analisi qualitativa delle mappe di errore}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Caratteristiche generali delle mappe di errore ViT}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Classi con anomalie estese}{20}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Esempio di mappa di errore per la classe \textit  {tile} con encoder ViT frozen. L’anomalia, di natura estesa e strutturata, produce una concentrazione visivamente riconoscibile dell’errore di ricostruzione. Nonostante una certa diffusione del segnale anche nelle regioni circostanti, la struttura spaziale del difetto risulta preservata, in accordo con i buoni valori di F1-score e IoU osservati.}}{21}{}\protected@file@percent }
\newlabel{fig:tile_vit_frozen}{{1}{21}{}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Mappa di errore di ricostruzione per la classe \textit  {wood} con encoder ViT frozen. L’errore risulta maggiormente concentrato in corrispondenza delle regioni difettose, sebbene a volte non perfettamente localizzato. Questo comportamento è coerente con le prestazioni quantitative relativamente elevate ottenute per questa classe.}}{21}{}\protected@file@percent }
\newlabel{fig:wood_vit_frozen}{{2}{21}{}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Esempio di heatmap per la classe \textit  {hazelnut} con encoder ViT frozen. Le anomalie estese generano una risposta di errore chiaramente distinguibile dallo sfondo, confermando che il Vision Transformer riesce a supportare la localizzazione quando il difetto presenta una struttura spaziale marcata.}}{22}{}\protected@file@percent }
\newlabel{fig:tile_vit_frozen}{{3}{22}{}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Classi con anomalie sottili o localizzate}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Mappa di errore di ricostruzione per la classe \textit  {screw} con encoder ViT frozen. Le anomalie, di dimensioni ridotte e localizzate lungo strutture sottili, non producono una concentrazione spaziale dell’errore. Il segnale risulta diffuso su gran parte dell’immagine, con un contrasto insufficiente tra regioni normali e anomale, rendendo inefficace la sogliatura statistica globale $\mu + \sigma $ e spiegando i bassi valori di F1-score e IoU osservati.}}{23}{}\protected@file@percent }
\newlabel{fig:screw_vit_frozen}{{4}{23}{}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Heatmap di ricostruzione per la classe \textit  {capsule} con encoder ViT frozen. L’errore di ricostruzione risulta scarsamente correlato alla posizione dell’anomalia, con una distribuzione spaziale uniforme che ostacola la localizzazione pixel-wise.}}{23}{}\protected@file@percent }
\newlabel{fig:capsule_vit_frozen}{{5}{23}{}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Mappa di errore per la classe \textit  {transistor} con encoder ViT frozen. L’anomalia, di dimensioni ridotte e ad alta frequenza spaziale, non produce una concentrazione localizzata dell’errore. Il segnale risulta diffuso su gran parte dell’immagine, rendendo inefficace la sogliatura globale e spiegando i bassi valori di F1-score e IoU osservati.}}{24}{}\protected@file@percent }
\newlabel{fig:transistor_vit_frozen}{{6}{24}{}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Esempio di mappa di errore per la classe \textit  {toothbrush} con encoder ViT frozen. La presenza di anomalie sottili e localizzate non si traduce in una risposta di errore spazialmente concentrata, confermando le difficoltà del Vision Transformer nel supportare la pipeline di localizzazione di AE-XAD in questi scenari.}}{24}{}\protected@file@percent }
\newlabel{fig:toothbrush_vit_frozen}{{7}{24}{}{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Confronto qualitativo tra ViT frozen e ViT trainable}{25}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confronto qualitativo tra encoder ViT frozen e trainable per la classe \textit  {tile}. Nel setting trainable si osserva una riduzione del contrasto tra regioni anomale e sfondo, con una mappa di errore più uniforme rispetto alla configurazione frozen.}}{26}{}\protected@file@percent }
\newlabel{fig:qual_tile_frozen_vs_trainable}{{8}{26}{}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Confronto tra mappe di errore per la classe \textit  {transistor} con encoder ViT frozen e trainable. Il fine-tuning end-to-end porta a una quasi completa soppressione del segnale di errore associato all’anomalia, rendendo inefficace la localizzazione pixel-wise.}}{27}{}\protected@file@percent }
\newlabel{fig:qual_transistor_frozen_vs_trainable}{{9}{27}{}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Sintesi dell’analisi qualitativa}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Discussione e conclusioni}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Discussione dei risultati}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Ruolo dell’inductive bias}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Frozen vs trainable: implicazioni}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Limiti del lavoro}{30}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Conclusioni e prospettive future}{30}{}\protected@file@percent }
\bibstyle{IEEEtran}
\bibdata{bibliography}
\bibcite{angiulli2025aexad}{1}
\gdef \@abspage@last{33}
