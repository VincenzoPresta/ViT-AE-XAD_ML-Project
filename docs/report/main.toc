\contentsline {section}{\numberline {1}Introduzione}{3}{}%
\contentsline {subsection}{\numberline {1.1}Definizione del Problema e Ipotesi di Ricerca}{3}{}%
\contentsline {section}{\numberline {2}Fondamenti teorici}{4}{}%
\contentsline {subsection}{\numberline {2.1}Anomaly Detection basata su ricostruzione}{4}{}%
\contentsline {subsection}{\numberline {2.2}Inductive bias nelle architetture di visione}{5}{}%
\contentsline {section}{\numberline {3}Il framework AE-XAD}{6}{}%
\contentsline {subsection}{\numberline {3.1}Architettura del modello}{6}{}%
\contentsline {subsection}{\numberline {3.2}Funzione di perdita AE-XAD}{6}{}%
\contentsline {subsection}{\numberline {3.3}Pipeline di scoring e localizzazione}{7}{}%
\contentsline {subsection}{\numberline {3.4}Assunzioni implicite del framework AE-XAD}{7}{}%
\contentsline {section}{\numberline {4}Modifica architetturale: integrazione del Vision Transformer}{9}{}%
\contentsline {subsection}{\numberline {4.1}Obiettivo della modifica}{9}{}%
\contentsline {subsection}{\numberline {4.2}Encoder ViT: struttura e adattamento spaziale}{9}{}%
\contentsline {subsection}{\numberline {4.3}Componenti mantenuti invariati}{10}{}%
\contentsline {subsection}{\numberline {4.4}Regimi di addestramento dell’encoder ViT}{10}{}%
\contentsline {subsubsection}{\numberline {4.4.1}Encoder ViT congelato}{10}{}%
\contentsline {subsubsection}{\numberline {4.4.2}Encoder ViT addestrabile}{11}{}%
\contentsline {subsection}{\numberline {4.5}Differenze strutturali rispetto all’encoder convoluzionale}{11}{}%
\contentsline {section}{\numberline {5}Setup sperimentale}{11}{}%
\contentsline {subsection}{\numberline {5.1}Dataset}{12}{}%
\contentsline {subsection}{\numberline {5.2}Protocollo few-shot supervisionato}{12}{}%
\contentsline {subsection}{\numberline {5.3}Preprocessing delle immagini}{13}{}%
\contentsline {subsection}{\numberline {5.4}Data augmentation}{13}{}%
\contentsline {subsection}{\numberline {5.5}Funzione di loss}{14}{}%
\contentsline {subsection}{\numberline {5.6}Ottimizzazione e dettagli di training}{14}{}%
\contentsline {subsection}{\numberline {5.7}Pipeline di training e test}{14}{}%
\contentsline {section}{\numberline {6}Risultati sperimentali}{15}{}%
\contentsline {subsection}{\numberline {6.1}Risultati quantitativi per classe (ViT frozen)}{15}{}%
\contentsline {subsection}{\numberline {6.2}Analisi delle prestazioni image-level}{16}{}%
\contentsline {subsection}{\numberline {6.3}Analisi delle prestazioni pixel-level}{16}{}%
\contentsline {subsection}{\numberline {6.4}Relazione tra rilevazione e localizzazione}{17}{}%
\contentsline {subsection}{\numberline {6.5}Sintesi dei risultati (ViT frozen)}{17}{}%
\contentsline {subsection}{\numberline {6.6}Risultati quantitativi per classe (ViT trainable)}{17}{}%
\contentsline {subsection}{\numberline {6.7}Confronto tra encoder ViT frozen e ViT trainable}{18}{}%
\contentsline {subsection}{\numberline {6.8}Confronto finale con AE-XAD originale}{19}{}%
\contentsline {section}{\numberline {7}Analisi qualitativa delle mappe di errore}{20}{}%
\contentsline {subsection}{\numberline {7.1}Caratteristiche generali delle mappe di errore ViT}{20}{}%
\contentsline {subsection}{\numberline {7.2}Classi con anomalie estese}{20}{}%
\contentsline {subsection}{\numberline {7.3}Classi con anomalie sottili o localizzate}{22}{}%
\contentsline {subsection}{\numberline {7.4}Confronto qualitativo tra ViT frozen e ViT trainable}{25}{}%
\contentsline {subsection}{\numberline {7.5}Sintesi dell’analisi qualitativa}{28}{}%
\contentsline {section}{\numberline {8}Discussione e conclusioni}{29}{}%
\contentsline {subsection}{\numberline {8.1}Discussione dei risultati}{29}{}%
\contentsline {subsection}{\numberline {8.2}Ruolo dell’inductive bias}{29}{}%
\contentsline {subsection}{\numberline {8.3}Frozen vs trainable: implicazioni}{29}{}%
\contentsline {subsection}{\numberline {8.4}Limiti del lavoro}{30}{}%
\contentsline {subsection}{\numberline {8.5}Conclusioni e prospettive future}{30}{}%
