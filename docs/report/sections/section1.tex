\newpage

\section{Introduzione}

L’Anomaly Detection in ambito industriale rappresenta un problema di grande rilevanza applicativa,
poiché consente l’individuazione automatica di difetti e anomalie su superfici e componenti prodotti
in serie. In molti scenari reali, le anomalie risultano rare, eterogenee e difficilmente annotabili
in modo esaustivo, rendendo complessa l’applicazione di approcci supervisionati tradizionali.
Per questo motivo, si sono affermati metodi basati su Autoencoder, capaci di apprendere una
rappresentazione delle sole istanze normali e di identificare le anomalie come deviazioni rispetto
al comportamento appreso.

All’interno di questo paradigma, i metodi di anomaly detection basati su ricostruzione hanno
dimostrato particolare efficacia in contesti industriali, soprattutto quando è richiesta una
localizzazione spaziale dei difetti. In tale direzione si colloca il framework AE-XAD, che introduce
una pipeline strutturata per la rilevazione e la localizzazione delle anomalie attraverso l’analisi
dell’errore di ricostruzione \cite{angiulli2025aexad}. Il metodo combina un encoder convoluzionale,
un decoder progettato per enfatizzare le discrepanze rispetto alla normalità e un meccanismo di
decisione basato su statistiche globali pixel-wise, ottenendo risultati competitivi sia a livello
di immagine che a livello di localizzazione.

Negli ultimi anni, l’evoluzione delle architetture di visione artificiale ha portato all’emergere di modelli
basati su meccanismi di attenzione globale, come i Vision Transformer, che hanno mostrato elevate
capacità di rappresentazione in numerosi compiti di visione artificiale. Questo progresso solleva
naturalmente l’interrogativo se tali architetture possano sostituire efficacemente le reti
convoluzionali anche all’interno di pipeline di anomaly detection basate su ricostruzione.

Tuttavia, l’integrazione di un Vision Transformer all’interno del framework AE-XAD non è immediata.
AE-XAD non è un autoencoder generico, ma un metodo che fa affidamento su specifiche assunzioni
strutturali riguardanti la distribuzione spaziale dell’errore di ricostruzione e sulla sua
separabilità statistica dal rumore di fondo. In questo contesto, la sostituzione dell’encoder
convoluzionale con un’architettura caratterizzata da un diverso tipo di rappresentazione solleva
interrogativi fondamentali sulla compatibilità tra il modello di features apprese e il meccanismo
decisionale adottato.

L’obiettivo di questo elaborato è quindi analizzare in modo sistematico se, e in quali condizioni,
un Vision Transformer possa sostituire l’encoder convoluzionale originale di AE-XAD mantenendo
inalterati il decoder, la funzione di loss, le metriche di valutazione e l’intera pipeline di test,
al fine di garantire un confronto equo e scientificamente rigoroso.

\subsection{Definizione del Problema e Ipotesi di Ricerca}

Il framework AE-XAD assume implicitamente che le anomalie producano errori di ricostruzione
\emph{spazialmente localizzati e compatti}, tali da poter essere distinti dal rumore di fondo mediante
una soglia statistica globale basata su media e deviazione standard ($\mu + \sigma$). Questa
assunzione risulta naturalmente coerente con le proprietà delle architetture convoluzionali, che
favoriscono una rappresentazione gerarchica e localmente strutturata delle informazioni spaziali.

Le architetture basate su attenzione globale, come i Vision Transformer, presentano invece un
comportamento rappresentazionale differente, orientato alla modellazione di relazioni globali tra
regioni dell’immagine. Sebbene tale caratteristica possa risultare vantaggiosa in compiti di natura
semantica, non è immediatamente evidente se essa sia compatibile con un paradigma di anomaly
detection basato su errori di ricostruzione pixel-wise e su una sogliatura statistica globale.

La domanda di ricerca che guida questo lavoro può pertanto essere formulata come segue:

\begin{quote}
\emph{Un Vision Transformer può sostituire efficacemente l’encoder convoluzionale di AE-XAD,
mantenendo inalterata la pipeline decisionale, in un contesto di anomaly detection few-shot
supervisionato?}
\end{quote}

L’ipotesi investigata in questa tesi è che, pur essendo in grado di apprendere rappresentazioni utili
per il ranking delle anomalie, i Vision Transformer tendano a produrre errori di ricostruzione più
diffusi e meno localizzati rispetto alle architetture convoluzionali. Di conseguenza, il meccanismo
di binarizzazione basato su $\mu + \sigma$ risulterebbe intrinsecamente meno efficace, portando a un
degrado delle prestazioni di localizzazione in specifiche classi del dataset considerato.
